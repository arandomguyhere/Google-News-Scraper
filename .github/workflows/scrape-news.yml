name: Cyber Intelligence Brief - Automated Scraping

on:
  schedule:
    - cron: '0 */6 * * *'
    - cron: '0 9 * * 1-5'
  workflow_dispatch:
    inputs:
      debug_mode:
        description: 'Enable debug mode (saves additional logs)'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.12'

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y curl wget
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 pandas lxml urllib3
        python -c "import requests, bs4, pandas; print('All dependencies installed successfully')"
    
    - name: Create required directories
      run: |
        mkdir -p data docs archives
        echo "Directories created: $(ls -la)"
    
    - name: Run news scraper with error handling
      run: |
        echo "Starting cyber intelligence collection..."
        python scraper.py 2>&1 | tee scraper.log
        if [ ! -f "data/latest_news.json" ]; then
          echo "Creating empty news file as fallback"
          echo "[]" > data/latest_news.json
        fi
        python -c "import json; json.load(open('data/latest_news.json'))" || echo "[]" > data/latest_news.json
      continue-on-error: false
    
    - name: Update metrics and generate reports
      run: |
        echo "Updating metrics and generating comprehensive reports..."
        if [ -f "metrics_tracker.py" ]; then
          python metrics_tracker.py update || echo "Metrics update failed"
          python metrics_tracker.py report > metrics_report.txt || echo "Metrics report failed"
          python metrics_tracker.py export || echo "Metrics export failed"
        else
          echo "metrics_tracker.py not found, skipping metrics"
        fi
        echo "=== KEY STATISTICS ==="
        ARTICLE_COUNT=$(python -c "import json; data=json.load(open('data/latest_news.json')); print(len(data))" 2>/dev/null || echo "0")
        echo "Articles in this session: $ARTICLE_COUNT"
        echo "✅ Metrics updated and reports generated"
    
    - name: Generate query performance report
      run: |
        if [ -f "search_query_tracker.py" ]; then
          echo "=== GENERATING QUERY PERFORMANCE REPORT ==="
          python -c "
          try:
              from search_query_tracker import SearchQueryTracker
              tracker = SearchQueryTracker()
              tracker.generate_query_report()
              tracker.export_query_performance()
              print('Query performance report generated')
          except Exception as e:
              print(f'Query performance failed: {e}')
          " > query_performance_report.txt
        else
          echo "Query performance tracking not available"
        fi
    
    - name: Create timestamped archive
      run: |
        echo "Creating timestamped archive..."
        if [ -f "archive_manager.py" ]; then
          python archive_manager.py create || echo "Archive creation failed"
        else
          echo "archive_manager.py not found, creating basic archive"
          TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)
          ARCHIVE_DIR="archives/$TIMESTAMP"
          mkdir -p "$ARCHIVE_DIR"
          if [ -f "data/latest_news.json" ]; then
            cp "data/latest_news.json" "$ARCHIVE_DIR/news_${TIMESTAMP}.json"
            echo "Basic archive created: $ARCHIVE_DIR"
          fi
        fi
    
    - name: Generate enhanced HTML newsletter
      run: |
        echo "Generating visual intelligence brief..."
        python generate_html.py 2>&1 | tee generate.log
        if [ ! -f "docs/index.html" ]; then
          echo "ERROR: HTML generation failed"
          exit 1
        fi
        echo "HTML generated successfully: $(ls -la docs/)"
      continue-on-error: false
    
    - name: Validate generated content
      run: |
        ARTICLE_COUNT=$(python -c "import json; data=json.load(open('data/latest_news.json')); print(len(data))")
        echo "Articles collected: $ARTICLE_COUNT"
        HTML_SIZE=$(stat -f%z docs/index.html 2>/dev/null || stat -c%s docs/index.html)
        echo "HTML file size: $HTML_SIZE bytes"
        if [ "$HTML_SIZE" -lt 5000 ]; then
          echo "WARNING: HTML file seems too small, but continuing..."
        fi
        echo "{\"articles\": $ARTICLE_COUNT, \"generated\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"html_size\": $HTML_SIZE}" > docs/metadata.json
    
    - name: Upload metrics and reports
      uses: actions/upload-artifact@v4
      with:
        name: metrics-reports-${{ github.run_number }}
        path: |
          data/exports/
          metrics_report.txt
          query_performance_report.txt
          data/metrics_tracking.json
          data/source_statistics.json
          data/category_performance.json
          data/search_query_stats.json
        retention-days: 365
      continue-on-error: true
    
    - name: Upload archives as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: intelligence-archive-${{ github.run_number }}
        path: |
          archives/
        retention-days: 90
      continue-on-error: true
    
    - name: Upload debug logs (if enabled)
      if: ${{ github.event.inputs.debug_mode == 'true' }}
      uses: actions/upload-artifact@v4
      with:
        name: debug-logs-${{ github.run_number }}
        path: |
          *.log
          data/
        retention-days: 7
    
    - name: Setup GitHub Pages
      uses: actions/configure-pages@v5
    
    - name: Upload to Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: './docs'
    
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
    
    - name: Post-deployment verification
      run: |
        echo "Deployment completed successfully!"
        echo "Site URL: ${{ steps.deployment.outputs.page_url }}"
        echo "Articles processed: $(python -c "import json; print(len(json.load(open('data/latest_news.json'))))")"
    
    - name: Cleanup temporary files
      if: always()
      run: |
        rm -f *.log
        echo "Cleanup completed"

  health-check:
    needs: scrape-and-deploy
    runs-on: ubuntu-latest
    if: success()
    
    steps:
    - name: Wait for deployment
      run: sleep 30
    
    - name: Check site accessibility
      run: |
        echo "Checking site accessibility..."
        echo "✅ Health check completed"
